{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = pd.read_csv(\"../Data/train.csv\")\n",
    "\n",
    "train = train.drop(\"id\", axis = 1)\n",
    "\n",
    "defect_counts = train[[\"Pastry\",\"Z_Scratch\",\"K_Scatch\",\"Stains\",\"Dirtiness\",\"Bumps\",\"Other_Faults\"]].sum(axis=1)\n",
    "train = train[defect_counts==1]\n",
    "\n",
    "train['target'] = train[[\"Pastry\",\"Z_Scratch\",\"K_Scatch\",\"Stains\",\"Dirtiness\",\"Bumps\",\"Other_Faults\"]].apply(lambda row: row.idxmax(), axis=1)\n",
    "train = train.drop([\"Pastry\",\"Z_Scratch\",\"K_Scatch\",\"Stains\",\"Dirtiness\",\"Bumps\",\"Other_Faults\"],axis = 1)\n",
    "\n",
    "label_map = {'Pastry': 0, 'Z_Scratch': 1, 'K_Scatch': 2, 'Stains': 3, 'Dirtiness': 4, 'Bumps': 5, 'Other_Faults': 6}\n",
    "train['target'] = train['target'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TypeOfSteel'] = train.apply(lambda row: 0 if row['TypeOfSteel_A300'] == 1 else (1 if row['TypeOfSteel_A400'] == 1 else None), axis=1)\n",
    "train = train.drop([\"TypeOfSteel_A300\", \"TypeOfSteel_A400\"], axis = 1)\n",
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:548: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "\n",
    "X = train.drop(\"target\", axis=1)\n",
    "y = train[\"target\"]\n",
    "\n",
    "multiroc = make_scorer(roc_auc_score, multi_class='ovo',needs_proba=True)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', [\"depthwise\", \"lossguide\"]),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0, log=True),\n",
    "        'gamma' : trial.suggest_float('gamma', 1e-9, 0.5),\n",
    "        'subsample': trial.suggest_float('subsample', 0.3, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 0, 12),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-9, 100.0, log=True),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-9, 100.0, log=True),\n",
    "        \n",
    "    }\n",
    "\n",
    "    cv_scores = cross_val_score(XGBClassifier(**params), X, y, cv=5, scoring=multiroc)\n",
    "\n",
    "    \n",
    "    return cv_scores.mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-04 14:46:40,628] A new study created in memory with name: no-name-300aa884-4554-4796-9a62-afb7b95cb4c5\n",
      "[I 2024-03-04 14:50:18,881] Trial 0 finished with value: 0.8973402045231953 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 803, 'learning_rate': 0.020141107046487246, 'gamma': 0.1767989045415461, 'subsample': 0.6771220571136365, 'colsample_bytree': 0.5477455763292887, 'max_depth': 9, 'min_child_weight': 6, 'reg_lambda': 0.010026470993996046, 'reg_alpha': 9.889751727227905e-07}. Best is trial 0 with value: 0.8973402045231953.\n",
      "[I 2024-03-04 14:50:41,145] Trial 1 finished with value: 0.885115145971562 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 347, 'learning_rate': 0.046909211849456046, 'gamma': 0.06033733534814755, 'subsample': 0.7360667937996177, 'colsample_bytree': 0.820626329243197, 'max_depth': 2, 'min_child_weight': 6, 'reg_lambda': 1.2813872103948067e-05, 'reg_alpha': 63.74581051275238}. Best is trial 0 with value: 0.8973402045231953.\n",
      "[I 2024-03-04 14:51:39,462] Trial 2 finished with value: 0.9025275879893282 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 521, 'learning_rate': 0.022820700513249498, 'gamma': 0.11852654512110541, 'subsample': 0.3616474973369075, 'colsample_bytree': 0.9304567410111284, 'max_depth': 5, 'min_child_weight': 7, 'reg_lambda': 7.615962735079892, 'reg_alpha': 6.791279310475334e-07}. Best is trial 2 with value: 0.9025275879893282.\n",
      "[I 2024-03-04 14:52:17,419] Trial 3 finished with value: 0.8827168094894555 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 534, 'learning_rate': 0.820485328701224, 'gamma': 0.05696169116660678, 'subsample': 0.9976821753198071, 'colsample_bytree': 0.9286784144925881, 'max_depth': 2, 'min_child_weight': 5, 'reg_lambda': 3.5105623990949126e-06, 'reg_alpha': 2.5419242753259986e-07}. Best is trial 2 with value: 0.9025275879893282.\n",
      "[I 2024-03-04 14:52:42,070] Trial 4 finished with value: 0.8994817380856859 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 124, 'learning_rate': 0.01887543951119677, 'gamma': 0.2075337464743085, 'subsample': 0.7354525860663136, 'colsample_bytree': 0.8006785895275246, 'max_depth': 6, 'min_child_weight': 2, 'reg_lambda': 9.251679095760657e-08, 'reg_alpha': 0.0004228284871340477}. Best is trial 2 with value: 0.9025275879893282.\n",
      "[I 2024-03-04 14:56:56,556] Trial 5 finished with value: 0.8999347345394924 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 558, 'learning_rate': 0.013518361168448295, 'gamma': 0.023062443367965726, 'subsample': 0.5702587640310779, 'colsample_bytree': 0.5951974974638266, 'max_depth': 11, 'min_child_weight': 6, 'reg_lambda': 0.002318999070653268, 'reg_alpha': 0.0006308373283375254}. Best is trial 2 with value: 0.9025275879893282.\n",
      "[I 2024-03-04 14:57:24,400] Trial 6 finished with value: 0.8550271680594015 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 313, 'learning_rate': 0.9891268337803351, 'gamma': 0.39061662280295983, 'subsample': 0.5082243992440202, 'colsample_bytree': 0.39464641629608105, 'max_depth': 6, 'min_child_weight': 1, 'reg_lambda': 0.010578863342515281, 'reg_alpha': 0.00010427971131456962}. Best is trial 2 with value: 0.9025275879893282.\n",
      "[I 2024-03-04 14:58:20,312] Trial 7 finished with value: 0.875689258712773 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 665, 'learning_rate': 0.46818655316076035, 'gamma': 0.15252502591120443, 'subsample': 0.6912593420557407, 'colsample_bytree': 0.9213574470444266, 'max_depth': 11, 'min_child_weight': 5, 'reg_lambda': 0.003745570780966294, 'reg_alpha': 8.654360753588967e-09}. Best is trial 2 with value: 0.9025275879893282.\n",
      "[I 2024-03-04 14:58:31,842] Trial 8 finished with value: 0.8948465221151112 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 206, 'learning_rate': 0.7393068726851157, 'gamma': 0.4844092633928101, 'subsample': 0.3477502114756924, 'colsample_bytree': 0.4409541270474219, 'max_depth': 2, 'min_child_weight': 5, 'reg_lambda': 58.35563104345913, 'reg_alpha': 4.768977507803308e-07}. Best is trial 2 with value: 0.9025275879893282.\n",
      "[I 2024-03-04 15:00:00,268] Trial 9 finished with value: 0.8986358645189471 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 309, 'learning_rate': 0.037701495192203185, 'gamma': 0.1843837214203681, 'subsample': 0.3893048616525261, 'colsample_bytree': 0.7349291846131188, 'max_depth': 12, 'min_child_weight': 3, 'reg_lambda': 25.797009640881104, 'reg_alpha': 8.446684205907614e-09}. Best is trial 2 with value: 0.9025275879893282.\n",
      "[I 2024-03-04 15:01:19,373] Trial 10 finished with value: 0.8904120683768987 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 961, 'learning_rate': 0.1557001846898351, 'gamma': 0.29992652952100796, 'subsample': 0.9218483698121878, 'colsample_bytree': 0.9698253605368204, 'max_depth': 4, 'min_child_weight': 7, 'reg_lambda': 0.58448756104127, 'reg_alpha': 0.21786853291608246}. Best is trial 2 with value: 0.9025275879893282.\n",
      "[I 2024-03-04 15:03:52,243] Trial 11 finished with value: 0.9020611069876476 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 527, 'learning_rate': 0.010274780793834223, 'gamma': 0.012851910523404642, 'subsample': 0.5110574269101282, 'colsample_bytree': 0.597387297764924, 'max_depth': 8, 'min_child_weight': 7, 'reg_lambda': 1.951717813230313e-09, 'reg_alpha': 0.0005922051608348873}. Best is trial 2 with value: 0.9025275879893282.\n",
      "[I 2024-03-04 15:06:10,108] Trial 12 finished with value: 0.9018210666754513 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 485, 'learning_rate': 0.01014541000539786, 'gamma': 0.0901662616118595, 'subsample': 0.4487086457057091, 'colsample_bytree': 0.6598348959258045, 'max_depth': 8, 'min_child_weight': 7, 'reg_lambda': 2.1223580739776307e-09, 'reg_alpha': 0.025031010042543378}. Best is trial 2 with value: 0.9025275879893282.\n",
      "[I 2024-03-04 15:08:35,366] Trial 13 finished with value: 0.8912257019150337 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 719, 'learning_rate': 0.04857898713446917, 'gamma': 0.004976869577997839, 'subsample': 0.3032862594220193, 'colsample_bytree': 0.5096524799910678, 'max_depth': 8, 'min_child_weight': 7, 'reg_lambda': 1.4166835869272252e-09, 'reg_alpha': 1.4582328766872306e-05}. Best is trial 2 with value: 0.9025275879893282.\n",
      "[I 2024-03-04 15:09:09,969] Trial 14 finished with value: 0.8966954484511589 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 466, 'learning_rate': 0.1135561357959673, 'gamma': 0.12043999630978505, 'subsample': 0.5615504716221528, 'colsample_bytree': 0.3024630051468968, 'max_depth': 4, 'min_child_weight': 4, 'reg_lambda': 1.3225739483896856e-05, 'reg_alpha': 0.02231970251744721}. Best is trial 2 with value: 0.9025275879893282.\n",
      "[I 2024-03-04 15:10:08,364] Trial 15 finished with value: 0.903691431180661 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 642, 'learning_rate': 0.028236538331317087, 'gamma': 0.32987692970003457, 'subsample': 0.4565512619749525, 'colsample_bytree': 0.6820807202374956, 'max_depth': 4, 'min_child_weight': 7, 'reg_lambda': 0.8821957356183572, 'reg_alpha': 1.0108304092499634e-09}. Best is trial 15 with value: 0.903691431180661.\n",
      "[I 2024-03-04 15:16:52,219] Trial 16 finished with value: 0.8909829469333644 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 860, 'learning_rate': 0.02852885715869826, 'gamma': 0.32658419953714657, 'subsample': 0.41011588183716163, 'colsample_bytree': 0.8363087825247333, 'max_depth': 0, 'min_child_weight': 4, 'reg_lambda': 0.6644532767943403, 'reg_alpha': 1.7827777417421474e-09}. Best is trial 15 with value: 0.903691431180661.\n",
      "[I 2024-03-04 15:18:13,822] Trial 17 finished with value: 0.8969712343402293 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 655, 'learning_rate': 0.07168925733031338, 'gamma': 0.2536585877384244, 'subsample': 0.45695923241945735, 'colsample_bytree': 0.6952741493671092, 'max_depth': 4, 'min_child_weight': 6, 'reg_lambda': 1.8559115475359913, 'reg_alpha': 8.895293517009908e-08}. Best is trial 15 with value: 0.903691431180661.\n",
      "[I 2024-03-04 15:19:15,696] Trial 18 finished with value: 0.878945465701281 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 393, 'learning_rate': 0.2127342504391818, 'gamma': 0.39796181532395347, 'subsample': 0.3123122244867441, 'colsample_bytree': 0.9937903485558092, 'max_depth': 5, 'min_child_weight': 3, 'reg_lambda': 0.08699361180176736, 'reg_alpha': 1.0824614451404217e-09}. Best is trial 15 with value: 0.903691431180661.\n",
      "[I 2024-03-04 15:20:12,710] Trial 19 finished with value: 0.9015951572306925 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 627, 'learning_rate': 0.07235714794004997, 'gamma': 0.26300861449456453, 'subsample': 0.5949123578645519, 'colsample_bytree': 0.7473190309427276, 'max_depth': 3, 'min_child_weight': 5, 'reg_lambda': 6.281613703033971, 'reg_alpha': 9.555691138081032e-06}. Best is trial 15 with value: 0.903691431180661.\n",
      "[I 2024-03-04 15:25:29,534] Trial 20 finished with value: 0.891860720373747 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 779, 'learning_rate': 0.02494636747887973, 'gamma': 0.36933884742513146, 'subsample': 0.3802558490345995, 'colsample_bytree': 0.872361945392657, 'max_depth': 0, 'min_child_weight': 7, 'reg_lambda': 0.0855613285456131, 'reg_alpha': 3.7911736072437104e-08}. Best is trial 15 with value: 0.903691431180661.\n",
      "[I 2024-03-04 15:27:35,243] Trial 21 finished with value: 0.9026614087241669 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 581, 'learning_rate': 0.010156545434104842, 'gamma': 0.09352018829472578, 'subsample': 0.5109237420467296, 'colsample_bytree': 0.5862594315957017, 'max_depth': 7, 'min_child_weight': 7, 'reg_lambda': 1.2791165530322173e-06, 'reg_alpha': 7.839670435715527e-06}. Best is trial 15 with value: 0.903691431180661.\n",
      "[I 2024-03-04 15:29:55,478] Trial 22 finished with value: 0.9024449603481666 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 605, 'learning_rate': 0.01579517102453899, 'gamma': 0.11656959470086847, 'subsample': 0.4650477968406262, 'colsample_bytree': 0.5050331888824937, 'max_depth': 7, 'min_child_weight': 6, 'reg_lambda': 0.00011600476266768107, 'reg_alpha': 4.546480162034622e-06}. Best is trial 15 with value: 0.903691431180661.\n",
      "[I 2024-03-04 15:31:33,394] Trial 23 finished with value: 0.9001447067153668 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 739, 'learning_rate': 0.0319739446531176, 'gamma': 0.2255767003898616, 'subsample': 0.62314795209356, 'colsample_bytree': 0.616375166206162, 'max_depth': 5, 'min_child_weight': 7, 'reg_lambda': 2.2648717240537932e-07, 'reg_alpha': 5.028689282050096e-05}. Best is trial 15 with value: 0.903691431180661.\n",
      "[I 2024-03-04 15:33:07,593] Trial 24 finished with value: 0.902375443423573 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 423, 'learning_rate': 0.014556535002530019, 'gamma': 0.4429179230375305, 'subsample': 0.5311291686150589, 'colsample_bytree': 0.7376682149271536, 'max_depth': 7, 'min_child_weight': 6, 'reg_lambda': 0.00016924731473502588, 'reg_alpha': 2.3842680709100486e-06}. Best is trial 15 with value: 0.903691431180661.\n",
      "[I 2024-03-04 15:35:09,151] Trial 25 finished with value: 0.9027142299325368 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 893, 'learning_rate': 0.02067582842517715, 'gamma': 0.32829012286062387, 'subsample': 0.42767620644228443, 'colsample_bytree': 0.44742899513574985, 'max_depth': 5, 'min_child_weight': 7, 'reg_lambda': 1.2263676178896727e-07, 'reg_alpha': 2.434045008738005e-08}. Best is trial 15 with value: 0.903691431180661.\n",
      "[I 2024-03-04 15:38:28,610] Trial 26 finished with value: 0.8884886270198395 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 982, 'learning_rate': 0.05821645818456611, 'gamma': 0.30603722343081485, 'subsample': 0.47257690190290325, 'colsample_bytree': 0.4112622160578955, 'max_depth': 9, 'min_child_weight': 6, 'reg_lambda': 2.1021797738829531e-07, 'reg_alpha': 2.308166089544703e-08}. Best is trial 15 with value: 0.903691431180661.\n",
      "[I 2024-03-04 15:39:36,821] Trial 27 finished with value: 0.9033318882669125 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 843, 'learning_rate': 0.013135181799813983, 'gamma': 0.343789487214841, 'subsample': 0.41852813023876523, 'colsample_bytree': 0.3356102945632988, 'max_depth': 3, 'min_child_weight': 7, 'reg_lambda': 4.621270374491524e-08, 'reg_alpha': 3.967007224646133e-09}. Best is trial 15 with value: 0.903691431180661.\n",
      "[I 2024-03-04 15:40:21,856] Trial 28 finished with value: 0.8971523741903941 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 867, 'learning_rate': 0.03579665668665478, 'gamma': 0.3451061932704275, 'subsample': 0.4171787988839979, 'colsample_bytree': 0.3544165820063261, 'max_depth': 1, 'min_child_weight': 5, 'reg_lambda': 1.937961447579624e-08, 'reg_alpha': 3.308276173066257e-09}. Best is trial 15 with value: 0.903691431180661.\n",
      "[I 2024-03-04 15:41:34,538] Trial 29 finished with value: 0.9047921671166457 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 884, 'learning_rate': 0.02094454919623795, 'gamma': 0.43310283194445315, 'subsample': 0.8241114159990148, 'colsample_bytree': 0.4604805638599247, 'max_depth': 3, 'min_child_weight': 6, 'reg_lambda': 1.588899068975288e-08, 'reg_alpha': 1.1166323197887553e-07}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 15:42:30,770] Trial 30 finished with value: 0.8916456844977636 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 806, 'learning_rate': 0.25273534923509183, 'gamma': 0.4426941272487993, 'subsample': 0.8643441672822724, 'colsample_bytree': 0.3057233062939232, 'max_depth': 3, 'min_child_weight': 6, 'reg_lambda': 2.5324035879876104e-08, 'reg_alpha': 1.1746829444683142e-07}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 15:43:49,521] Trial 31 finished with value: 0.904770145988396 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 919, 'learning_rate': 0.01971763697299352, 'gamma': 0.41588305171700934, 'subsample': 0.8083186246705132, 'colsample_bytree': 0.47697293070782837, 'max_depth': 3, 'min_child_weight': 7, 'reg_lambda': 2.0939256965650586e-08, 'reg_alpha': 1.3323012271322838e-08}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 15:45:11,591] Trial 32 finished with value: 0.9046196432443837 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 918, 'learning_rate': 0.016047927897033906, 'gamma': 0.43001932380324615, 'subsample': 0.820925963851876, 'colsample_bytree': 0.5330809285215645, 'max_depth': 3, 'min_child_weight': 6, 'reg_lambda': 1.1391596030886958e-08, 'reg_alpha': 1.140199254952406e-09}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 15:46:00,282] Trial 33 finished with value: 0.8918446796739381 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 919, 'learning_rate': 0.017935734247273762, 'gamma': 0.43283728868318616, 'subsample': 0.8149252186868635, 'colsample_bytree': 0.515606296277919, 'max_depth': 1, 'min_child_weight': 6, 'reg_lambda': 8.213838646064474e-09, 'reg_alpha': 1.1705706873236821e-08}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 15:47:03,975] Trial 34 finished with value: 0.9037804363775533 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 937, 'learning_rate': 0.023793392665618057, 'gamma': 0.4959001606521119, 'subsample': 0.8018555722950811, 'colsample_bytree': 0.5481557237653386, 'max_depth': 2, 'min_child_weight': 5, 'reg_lambda': 8.917353392231982e-07, 'reg_alpha': 1.0614229202833282e-09}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 15:48:04,128] Trial 35 finished with value: 0.8965678275293275 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 998, 'learning_rate': 0.043528486480348356, 'gamma': 0.4849146549199907, 'subsample': 0.8044922596381149, 'colsample_bytree': 0.46999101395577175, 'max_depth': 2, 'min_child_weight': 5, 'reg_lambda': 1.1947287008233644e-06, 'reg_alpha': 28.692464316151334}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 15:48:52,828] Trial 36 finished with value: 0.8941419323840469 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 934, 'learning_rate': 0.02141326038058542, 'gamma': 0.4961723654424107, 'subsample': 0.7662586842274893, 'colsample_bytree': 0.5365293754873804, 'max_depth': 1, 'min_child_weight': 4, 'reg_lambda': 5.4955102259480464e-09, 'reg_alpha': 7.336296838432461e-07}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 15:49:59,906] Trial 37 finished with value: 0.9044151767065911 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 810, 'learning_rate': 0.022747623311993207, 'gamma': 0.4163200389815721, 'subsample': 0.9094769287937212, 'colsample_bytree': 0.5633406520891313, 'max_depth': 3, 'min_child_weight': 5, 'reg_lambda': 9.93059154159279e-06, 'reg_alpha': 1.6010147030913756e-07}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 15:51:08,733] Trial 38 finished with value: 0.9037435404803963 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 805, 'learning_rate': 0.013689670092950622, 'gamma': 0.417633910630098, 'subsample': 0.921375200472323, 'colsample_bytree': 0.4756191731633779, 'max_depth': 3, 'min_child_weight': 6, 'reg_lambda': 1.6242141992876836e-05, 'reg_alpha': 1.0980552888340735e-07}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 15:51:45,341] Trial 39 finished with value: 0.8884276902719389 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 705, 'learning_rate': 0.018360264973870725, 'gamma': 0.45767903413486055, 'subsample': 0.9872316687748317, 'colsample_bytree': 0.5671724828103576, 'max_depth': 1, 'min_child_weight': 4, 'reg_lambda': 7.786318184320348e-09, 'reg_alpha': 1.0935335485271416e-06}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 15:52:52,681] Trial 40 finished with value: 0.9035945159377409 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 828, 'learning_rate': 0.037796446653489885, 'gamma': 0.3829250850672321, 'subsample': 0.8612900019873968, 'colsample_bytree': 0.41376725169229905, 'max_depth': 3, 'min_child_weight': 5, 'reg_lambda': 0.0006205974071642271, 'reg_alpha': 2.24576140356553e-07}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 15:53:51,456] Trial 41 finished with value: 0.9038315644699699 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 925, 'learning_rate': 0.02364733549665914, 'gamma': 0.4648291763648053, 'subsample': 0.6912772594481401, 'colsample_bytree': 0.6263438067804123, 'max_depth': 2, 'min_child_weight': 5, 'reg_lambda': 6.851350929958524e-07, 'reg_alpha': 4.960354808771866e-09}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 15:54:54,647] Trial 42 finished with value: 0.9025792939717677 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 899, 'learning_rate': 0.01726089195009113, 'gamma': 0.46476261581784684, 'subsample': 0.6772857705258979, 'colsample_bytree': 0.6467076331878278, 'max_depth': 2, 'min_child_weight': 6, 'reg_lambda': 5.686313634449642e-06, 'reg_alpha': 6.944535309020307e-09}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 15:56:23,450] Trial 43 finished with value: 0.9038438297532359 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 764, 'learning_rate': 0.026421862050491966, 'gamma': 0.4134819409587651, 'subsample': 0.7284901087242877, 'colsample_bytree': 0.4695465007875974, 'max_depth': 4, 'min_child_weight': 5, 'reg_lambda': 4.479761702756453e-07, 'reg_alpha': 4.2410348196418396e-08}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 15:57:42,742] Trial 44 finished with value: 0.9044289079643534 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 765, 'learning_rate': 0.012751615935953873, 'gamma': 0.4113780769566642, 'subsample': 0.7243241316531217, 'colsample_bytree': 0.3766934243509187, 'max_depth': 4, 'min_child_weight': 3, 'reg_lambda': 3.289548666329214e-05, 'reg_alpha': 3.0452556387439275e-08}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 15:59:46,789] Trial 45 finished with value: 0.9043687547432946 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 877, 'learning_rate': 0.012289172674816733, 'gamma': 0.368429052256633, 'subsample': 0.8624677497398425, 'colsample_bytree': 0.3749032300422512, 'max_depth': 5, 'min_child_weight': 3, 'reg_lambda': 5.4521548917131735e-05, 'reg_alpha': 2.1152329932717424e-07}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 16:01:54,944] Trial 46 finished with value: 0.9029292928968689 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 695, 'learning_rate': 0.015975012477563208, 'gamma': 0.4136118800922933, 'subsample': 0.911739660107397, 'colsample_bytree': 0.43718124512298184, 'max_depth': 6, 'min_child_weight': 2, 'reg_lambda': 0.0011372056587511282, 'reg_alpha': 1.7092073113378e-06}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 16:03:16,620] Trial 47 finished with value: 0.9046152975533932 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 766, 'learning_rate': 0.020185826224347524, 'gamma': 0.39553564522648665, 'subsample': 0.7592443689494696, 'colsample_bytree': 0.38142560018592425, 'max_depth': 4, 'min_child_weight': 2, 'reg_lambda': 4.0612276235216684e-05, 'reg_alpha': 1.562080305934091e-08}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 16:04:45,932] Trial 48 finished with value: 0.9045190981150277 and parameters: {'grow_policy': 'lossguide', 'n_estimators': 767, 'learning_rate': 0.01205922404751116, 'gamma': 0.3877441514864292, 'subsample': 0.7560317757124921, 'colsample_bytree': 0.38506346696909793, 'max_depth': 4, 'min_child_weight': 2, 'reg_lambda': 5.6428040736687246e-08, 'reg_alpha': 4.8349925848552576e-08}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 16:06:09,852] Trial 49 finished with value: 0.9046445951607422 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 963, 'learning_rate': 0.011518171667561406, 'gamma': 0.2797502813187318, 'subsample': 0.773055919545921, 'colsample_bytree': 0.34205511912271236, 'max_depth': 4, 'min_child_weight': 1, 'reg_lambda': 6.703821392532582e-08, 'reg_alpha': 0.0037892450968552522}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 16:07:03,583] Trial 50 finished with value: 0.8800362629080279 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 959, 'learning_rate': 0.5246112785223471, 'gamma': 0.28155247717109766, 'subsample': 0.8397488036399198, 'colsample_bytree': 0.41910455902758215, 'max_depth': 5, 'min_child_weight': 1, 'reg_lambda': 4.125741734997103e-09, 'reg_alpha': 0.002633149440311201}. Best is trial 29 with value: 0.9047921671166457.\n",
      "[I 2024-03-04 16:08:22,280] Trial 51 finished with value: 0.9047961134916285 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 970, 'learning_rate': 0.011433720556350141, 'gamma': 0.37671773389299923, 'subsample': 0.7622989070701647, 'colsample_bytree': 0.33440542784129323, 'max_depth': 4, 'min_child_weight': 2, 'reg_lambda': 3.186246584765799e-08, 'reg_alpha': 0.0024920742751454263}. Best is trial 51 with value: 0.9047961134916285.\n",
      "[I 2024-03-04 16:10:22,099] Trial 52 finished with value: 0.9028956961082262 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 964, 'learning_rate': 0.010252196568532032, 'gamma': 0.3605610392994573, 'subsample': 0.7550646654755537, 'colsample_bytree': 0.34155034367638304, 'max_depth': 6, 'min_child_weight': 1, 'reg_lambda': 1.0173980003266452e-09, 'reg_alpha': 0.004172356441598058}. Best is trial 51 with value: 0.9047961134916285.\n",
      "[I 2024-03-04 16:11:37,090] Trial 53 finished with value: 0.9047834666798031 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 887, 'learning_rate': 0.01850067095302448, 'gamma': 0.19658226370297355, 'subsample': 0.7841358680950687, 'colsample_bytree': 0.32548745017732433, 'max_depth': 4, 'min_child_weight': 2, 'reg_lambda': 2.09120888933891e-08, 'reg_alpha': 0.13928805512009998}. Best is trial 51 with value: 0.9047961134916285.\n",
      "[I 2024-03-04 16:12:42,111] Trial 54 finished with value: 0.9024486425603928 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 1000, 'learning_rate': 0.015498662142766993, 'gamma': 0.20419381335671805, 'subsample': 0.7819216686652013, 'colsample_bytree': 0.3222368418928978, 'max_depth': 2, 'min_child_weight': 1, 'reg_lambda': 1.7787405619988792e-08, 'reg_alpha': 0.11378651408203876}. Best is trial 51 with value: 0.9047961134916285.\n",
      "[I 2024-03-04 16:13:50,670] Trial 55 finished with value: 0.9034669572380478 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 905, 'learning_rate': 0.011951944815440936, 'gamma': 0.22208330487723718, 'subsample': 0.8338561532333719, 'colsample_bytree': 0.49099950751211385, 'max_depth': 3, 'min_child_weight': 2, 'reg_lambda': 2.554469222238896e-08, 'reg_alpha': 2.786919821425507}. Best is trial 51 with value: 0.9047961134916285.\n",
      "[I 2024-03-04 16:15:23,588] Trial 56 finished with value: 0.9004844071396908 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 849, 'learning_rate': 0.0323541912587519, 'gamma': 0.17153994149945828, 'subsample': 0.7103740453923195, 'colsample_bytree': 0.3542318541709564, 'max_depth': 5, 'min_child_weight': 1, 'reg_lambda': 1.9021696352241417e-07, 'reg_alpha': 0.00023294666427676157}. Best is trial 51 with value: 0.9047961134916285.\n",
      "[I 2024-03-04 16:16:44,514] Trial 57 finished with value: 0.9048980956626519 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 965, 'learning_rate': 0.018777572067517182, 'gamma': 0.14148142646105832, 'subsample': 0.8832991131065054, 'colsample_bytree': 0.4470665546798871, 'max_depth': 3, 'min_child_weight': 2, 'reg_lambda': 2.8552722260874556e-09, 'reg_alpha': 0.0019666192647892623}. Best is trial 57 with value: 0.9048980956626519.\n",
      "[I 2024-03-04 16:16:55,650] Trial 58 finished with value: 0.9032697672049641 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 112, 'learning_rate': 0.10708622667869014, 'gamma': 0.14236982382729868, 'subsample': 0.6498337645995746, 'colsample_bytree': 0.31889510815049643, 'max_depth': 4, 'min_child_weight': 2, 'reg_lambda': 2.7961960120292723e-09, 'reg_alpha': 0.002755608113629738}. Best is trial 57 with value: 0.9048980956626519.\n",
      "[I 2024-03-04 16:18:52,746] Trial 59 finished with value: 0.8986185260744198 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 938, 'learning_rate': 0.02940581413523155, 'gamma': 0.1788318855535685, 'subsample': 0.888956538279216, 'colsample_bytree': 0.4335830590079251, 'max_depth': 6, 'min_child_weight': 3, 'reg_lambda': 4.9662255748248825e-08, 'reg_alpha': 0.01315170555867119}. Best is trial 57 with value: 0.9048980956626519.\n",
      "[I 2024-03-04 16:20:12,255] Trial 60 finished with value: 0.8985473522578177 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 968, 'learning_rate': 0.055492613604290766, 'gamma': 0.1571749987235922, 'subsample': 0.9524841370168697, 'colsample_bytree': 0.3957415665275564, 'max_depth': 4, 'min_child_weight': 2, 'reg_lambda': 2.1887847377835467e-06, 'reg_alpha': 0.12339968289237564}. Best is trial 57 with value: 0.9048980956626519.\n",
      "[I 2024-03-04 16:20:28,886] Trial 61 finished with value: 0.8963692594630377 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 220, 'learning_rate': 0.0189677418142287, 'gamma': 0.2046290477847273, 'subsample': 0.7888560821260656, 'colsample_bytree': 0.4456977275371695, 'max_depth': 3, 'min_child_weight': 1, 'reg_lambda': 1.0004089032589209e-08, 'reg_alpha': 0.0008103952791626868}. Best is trial 57 with value: 0.9048980956626519.\n",
      "[I 2024-03-04 16:21:34,447] Trial 62 finished with value: 0.904325079228942 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 882, 'learning_rate': 0.014647711644516457, 'gamma': 0.06932353243168032, 'subsample': 0.8302658050731, 'colsample_bytree': 0.3554703247458774, 'max_depth': 3, 'min_child_weight': 2, 'reg_lambda': 8.91215274073993e-08, 'reg_alpha': 0.6231279761397364}. Best is trial 57 with value: 0.9048980956626519.\n",
      "[I 2024-03-04 16:22:32,818] Trial 63 finished with value: 0.9000160595072204 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 959, 'learning_rate': 0.011139327235197326, 'gamma': 0.13165273506561792, 'subsample': 0.893724026473112, 'colsample_bytree': 0.5259980625875665, 'max_depth': 2, 'min_child_weight': 3, 'reg_lambda': 2.4157606428374337e-09, 'reg_alpha': 0.001296030443443196}. Best is trial 57 with value: 0.9048980956626519.\n",
      "[I 2024-03-04 16:23:45,712] Trial 64 finished with value: 0.9045413749678046 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 841, 'learning_rate': 0.01646650224614085, 'gamma': 0.23600448842528543, 'subsample': 0.9536684984072035, 'colsample_bytree': 0.48635898204292943, 'max_depth': 4, 'min_child_weight': 1, 'reg_lambda': 1.5043634571115966e-08, 'reg_alpha': 5.782261825532035e-05}. Best is trial 57 with value: 0.9048980956626519.\n",
      "[I 2024-03-04 16:27:59,345] Trial 65 finished with value: 0.8969518478598439 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 893, 'learning_rate': 0.013599429991124528, 'gamma': 0.299728882782155, 'subsample': 0.7788005202138775, 'colsample_bytree': 0.30085604482390466, 'max_depth': 12, 'min_child_weight': 2, 'reg_lambda': 3.6080956699842984e-07, 'reg_alpha': 0.008138404933007916}. Best is trial 57 with value: 0.9048980956626519.\n",
      "[I 2024-03-04 16:29:06,917] Trial 66 finished with value: 0.8930156512306983 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 999, 'learning_rate': 0.14031334237404533, 'gamma': 0.4322131251959303, 'subsample': 0.8534238411114093, 'colsample_bytree': 0.4634396768945156, 'max_depth': 5, 'min_child_weight': 1, 'reg_lambda': 4.090300560713556e-08, 'reg_alpha': 0.05165477327641572}. Best is trial 57 with value: 0.9048980956626519.\n",
      "[I 2024-03-04 16:30:22,967] Trial 67 finished with value: 0.9049037151323628 and parameters: {'grow_policy': 'depthwise', 'n_estimators': 941, 'learning_rate': 0.019761611796128387, 'gamma': 0.273437747265095, 'subsample': 0.8240560571034576, 'colsample_bytree': 0.4115236844325919, 'max_depth': 3, 'min_child_weight': 2, 'reg_lambda': 4.268013260440379e-09, 'reg_alpha': 0.0002730493609398887}. Best is trial 67 with value: 0.9049037151323628.\n",
      "[W 2024-03-04 16:32:57,341] Trial 68 failed with parameters: {'grow_policy': 'depthwise', 'n_estimators': 944, 'learning_rate': 0.019982000968296307, 'gamma': 0.2440438687670589, 'subsample': 0.7098881365588366, 'colsample_bytree': 0.4006465031410592, 'max_depth': 11, 'min_child_weight': 3, 'reg_lambda': 1.1279074004901375e-09, 'reg_alpha': 0.00016170169605040488} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Janith\\AppData\\Local\\Temp\\ipykernel_15988\\2479969456.py\", line 26, in objective\n",
      "    cv_scores = cross_val_score(XGBClassifier(**params), X, y, cv=5, scoring=multiroc)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 719, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "                 ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 430, in cross_validate\n",
      "    results = parallel(\n",
      "              ^^^^^^^^^\n",
      "  File \"c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 67, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1088, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 129, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1519, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 2051, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2024-03-04 16:32:57,357] Trial 68 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     _optimize(\n\u001b[0;32m    452\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    453\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    454\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    455\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    456\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    457\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    458\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    459\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    460\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    461\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[25], line 26\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(trial):\n\u001b[0;32m     12\u001b[0m     params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrow_policy\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrow_policy\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdepthwise\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlossguide\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1000\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \n\u001b[0;32m     24\u001b[0m     }\n\u001b[1;32m---> 26\u001b[0m     cv_scores \u001b[38;5;241m=\u001b[39m cross_val_score(XGBClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams), X, y, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39mmultiroc)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cv_scores\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[0;32m    720\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    721\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    722\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    723\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m    724\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[0;32m    725\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[0;32m    726\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    727\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    728\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[0;32m    729\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    730\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[0;32m    731\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    732\u001b[0m )\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    431\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    432\u001b[0m         clone(estimator),\n\u001b[0;32m    433\u001b[0m         X,\n\u001b[0;32m    434\u001b[0m         y,\n\u001b[0;32m    435\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[0;32m    436\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    437\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    438\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    439\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    440\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[0;32m    441\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n\u001b[0;32m    442\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m    443\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    444\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[0;32m    445\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    446\u001b[0m     )\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    448\u001b[0m )\n\u001b[0;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 895\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1519\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1491\u001b[0m (\n\u001b[0;32m   1492\u001b[0m     model,\n\u001b[0;32m   1493\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1499\u001b[0m )\n\u001b[0;32m   1500\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1501\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1502\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1517\u001b[0m )\n\u001b[1;32m-> 1519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1520\u001b[0m     params,\n\u001b[0;32m   1521\u001b[0m     train_dmatrix,\n\u001b[0;32m   1522\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[0;32m   1523\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[0;32m   1524\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39mearly_stopping_rounds,\n\u001b[0;32m   1525\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[0;32m   1526\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[0;32m   1527\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m   1528\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1529\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   1530\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   1531\u001b[0m )\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     _check_call(\n\u001b[1;32m-> 2051\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[0;32m   2052\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration), dtrain\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   2053\u001b[0m         )\n\u001b[0;32m   2054\u001b[0m     )\n\u001b[0;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "`Study.stop` is supposed to be invoked inside an objective function or a callback.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m study\u001b[38;5;241m.\u001b[39mstop()\n",
      "File \u001b[1;32mc:\\Users\\Janith\\anaconda3\\Lib\\site-packages\\optuna\\study\\study.py:800\u001b[0m, in \u001b[0;36mStudy.stop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Exit from the current optimization loop after the running trials finish.\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \n\u001b[0;32m    773\u001b[0m \u001b[38;5;124;03mThis method lets the running :meth:`~optuna.study.Study.optimize` method return\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    796\u001b[0m \n\u001b[0;32m    797\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread_local\u001b[38;5;241m.\u001b[39min_optimize_loop:\n\u001b[1;32m--> 800\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    801\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Study.stop` is supposed to be invoked inside an objective function or a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    802\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    803\u001b[0m     )\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: `Study.stop` is supposed to be invoked inside an objective function or a callback."
     ]
    }
   ],
   "source": [
    "study.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
